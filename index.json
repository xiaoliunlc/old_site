[{"authors":["admin"],"categories":null,"content":"I am a third year Ph.D. candidate majoring in Computer Science at School of Computer Science \u0026amp; Technology, Beijing Institute of Technology. My research interests are mainly focused on Natural language processing (especially Event Extraction and Event Schema Induction) with machine learning approaches.\nMy Ph.D. supervisor is professor Heyan Huang.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://xiaoliubit.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a third year Ph.D. candidate majoring in Computer Science at School of Computer Science \u0026amp; Technology, Beijing Institute of Technology. My research interests are mainly focused on Natural language processing (especially Event Extraction and Event Schema Induction) with machine learning approaches.","tags":null,"title":"Xiao Liu","type":"authors"},{"authors":["Qingkai Min","Libo Qin","Zhiyang Teng","Xiao Liu","Yue Zhang"],"categories":[],"content":"","date":1594396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594396800,"objectID":"ce8992a170da2e1fec431acc510c7271","permalink":"https://xiaoliubit.github.io/publication/ijcai2020-dsi/","publishdate":"2020-04-25T00:00:00+08:00","relpermalink":"/publication/ijcai2020-dsi/","section":"publication","summary":"Dialogue state modules are a useful component in a task-oriented dialogue system. Traditional methods find dialogue states by manually labeling training corpora, upon which neural models are trained. However, the labeling process can be costly, slow, error-prone, and more importantly, cannot cover the vast range of domains in real-world dialogues for customer service. We propose the task of dialogue state induction, building two neural latent variable models that mine dialogue states automatically from unlabeled customer service dialogue records. Results show that the models can effectively find meaningful dialogue states. In addition, equipped with induced dialogue states, a state-ofthe-art dialogue system gives better performance compared with not using a dialogue state module.","tags":[],"title":"Dialogue State Induction Using Neural Latent Variable Models","type":"publication"},{"authors":["Xiao Liu","Heyan Huang","Yue Zhang","Changsen Yuan"],"categories":[],"content":"","date":1585929600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585929600,"objectID":"171dbf688461667246e708c11351c9c8","permalink":"https://xiaoliubit.github.io/publication/arxiv-stock/","publishdate":"2020-04-04T00:00:00+08:00","relpermalink":"/publication/arxiv-stock/","section":"publication","summary":"We consider direct modeling of underlying stock value movement sequences over time in the news-driven stock movement prediction. A recurrent state transition model is constructed, which better captures a gradual process of stock movement continuously by modeling the correlation between past and future price movements. By separating the effects of news and noise, a noisy random factor is also explicitly fitted based on the recurrent states. Results show that the proposed model outperforms strong baselines. Thanks to the use of attention over news events, our model is also more explainable. To our knowledge, we are the first to explicitly model both events and noise over a fundamental stock value state for news-driven stock movement prediction.","tags":[],"title":"News-Driven Stock Prediction With Attention-Based Noisy Recurrent State Transition","type":"publication"},{"authors":["Xiao Liu","Heyan Huang","Yue Zhang"],"categories":[],"content":"","date":1557763200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557763200,"objectID":"a4c027825f1125c703c1a80e4399977c","permalink":"https://xiaoliubit.github.io/publication/acl2019-odee/","publishdate":"2019-05-14T00:00:00+08:00","relpermalink":"/publication/acl2019-odee/","section":"publication","summary":"We consider open domain event extraction, the task of extracting unconstraint types of events from news clusters. A novel latent variable neural model is constructed, which is scalable to very large corpus. A dataset is collected and manually annotated, with task-specific evaluation metrics being designed. Results show that the proposed unsupervised model gives better performance compared to the state-of-the-art method for event schema induction.","tags":[],"title":"Open Domain Event Extraction Using Neural Latent Variable Models","type":"publication"},{"authors":["Changsen Yuan","Heyan Huang","Chong Feng","Xiao Liu","Xiaochi Wei"],"categories":[],"content":"","date":1548518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548518400,"objectID":"8bc7292fb30260749d39d54e4291594a","permalink":"https://xiaoliubit.github.io/publication/aaai2019-re/","publishdate":"2019-01-27T00:00:00+08:00","relpermalink":"/publication/aaai2019-re/","section":"publication","summary":"Distant supervision for relation extraction is an efficient method to reduce labor costs and has been widely used to seek novel relational facts in large corpora, which can be identified as a multi-instance multi-label problem. However, existing distant supervision methods suffer from selecting important words in the sentence and extracting valid sentences in the bag. Towards this end, we propose a novel approach to address these problems in this paper. Firstly, we propose a linear attenuation simulation to reflect the importance of words in the sentence with respect to the distances between entities and words. Secondly, we propose a non-independent and identically distributed (non-IID) relevance embedding to capture the relevance of sentences in the bag. Our method can not only capture complex information of words about hidden relations, but also express the mutual information of instances in the bag. Extensive experiments on a benchmark dataset have well-validated the effectiveness of the proposed method.","tags":[],"title":"Distant Supervision for Relation Extraction with Linear Attenuation Simulation and Non-IID Relevance Embedding","type":"publication"},{"authors":["Xiao Liu","Zhunchen Luo","Heyan Huang"],"categories":[],"content":"","date":1530374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530374400,"objectID":"ecdb6ea00ba15bc3e8719a7f840a3bd8","permalink":"https://xiaoliubit.github.io/publication/emnlp2018-multiee/","publishdate":"2018-07-01T00:00:00+08:00","relpermalink":"/publication/emnlp2018-multiee/","section":"publication","summary":"Event extraction is of practical utility in natural language processing. In the real world, it is a common phenomenon that multiple events existing in the same sentence, where extracting them are more difficult than extracting a single event. Previous works on modeling the associations between events by sequential modeling methods suffer a lot from the low efficiency in capturing very long-range dependencies. In this paper, we propose a novel Jointly Multiple Events Extraction (JMEE) framework to jointly extract multiple event triggers and arguments by introducing syntactic shortcut arcs to enhance information flow and attention-based graph convolution networks to model graph information. The experiment results demonstrate that our proposed framework achieves competitive results compared with state-of-the-art methods.","tags":[],"title":"Jointly Multiple Events Extraction via Attention-based Graph Information Aggregation","type":"publication"},{"authors":["Zhunchen Luo","Xiao Liu"],"categories":[],"content":"","date":1527782400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527782400,"objectID":"f998eaeefd189249b57de57579a0cdee","permalink":"https://xiaoliubit.github.io/publication/coling2018-paperaccepted/","publishdate":"2018-06-01T00:00:00+08:00","relpermalink":"/publication/coling2018-paperaccepted/","section":"publication","summary":"Twitter has become one of the most import channels to spread latest scholarly information because of its fast information spread speed. How to predict whether a scholarly tweet will be retweeted is a key task in understanding the message propagation within large user communities. Hence, we present the real-time scholarly retweeting prediction system that retrieves scholarly tweets which will be retweeted. First, we filter scholarly tweets from tracking a tweet stream. Then, we extract Tweet Scholar Blocks indicating metadata of papers. At last, we combine scholarly features with the Tweet Scholar Blocks to predict whether a scholarly tweet will be retweeted. Our system outperforms chosen baseline systems. Additionally, our system has the potential to predict scientific impact in real-time.","tags":[],"title":"Real-time Scholarly Retweeting Prediction System","type":"publication"}]